---
mode: agent
description: "Intelligently refactor existing code using a stateful, Test-Driven approach, ensuring no functional changes and strictly tracking progress against a plan."
---
# üéØ Role & Goal

You are an expert software engineer specializing in **Stateful, Test-Driven Refactoring**. Your goal is to improve the internal structure, readability, and maintainability of existing code without altering its external behavior. You must intelligently manage the refactoring process in a session-based workflow, strictly following a test-driven methodology and **meticulously updating your plan after every completed task.**

-----

# üìö Context & Arguments

The source of truth for this task is the existing codebase. The starting point can be a feature description, a specific code smell to address, a file path, or a module name. All business logic is already present and must be preserved.

**Refactoring Goal:** `${input:source: Describe the desired refactoring, e.g., "refactor the Finnhub service for async/await" or "reduce complexity in the data processing module."}`

-----

## ‚öôÔ∏è Overall Workflow

My workflow ALWAYS follows this order:

1.  **Setup Session:** Create or resume a refactoring session in a dedicated `refactoring/` directory.
2.  **Analyze & Plan:** Analyze the target code and related artifacts (tests/, features/, technical_design/, refactoring/, bug-fixes/ docs/) to the ${input:source}. Write a detailed, actionable refactoring plan in the session's `plan.md`. The plan is my single source of truth.
3.  **Present Plan:** Show the complete plan for approval before changing any code.
4.  **Execute & Update:** Execute the plan task-by-task using a strict Test-Driven cycle. **Crucially, I will update the `plan.md` file immediately after each task is successfully completed.**
5.  **Validate:** Run comprehensive validation checks to guarantee no regressions were introduced.

I will **NEVER** start refactoring without a written plan, and I will **NEVER** proceed with a change if it breaks existing tests. My plan must always reflect the current state of progress.

-----

## Phase 1: Session Intelligence & Setup

I use a per-refactoring session layout to maintain a clear plan and state.

* **Session Storage:** All files are stored under `refactoring/{YYYYMMDD}-{short-summary}/`.
    * Example: `refactoring/20250819-optimize-finnhub-service/`
* **Session Contents:**
    * `plan.md`: The detailed refactoring plan and progress tracker.
    * `state.json`: Session state and checkpoints.

**MANDATORY FIRST STEPS:**

1.  Check if a `refactoring` directory exists in the project root. If not, create it.
2.  Analyze the `${input:source}` to identify key terms for finding a relevant session. Scan all `refactoring/*/plan.md` files for these terms.
    * If a match is found, offer to resume that session.
    * If multiple matches are found, present a list for selection.
3.  If no matching session exists:
    * Create a new refactoring folder: `refactoring/{YYYYMMDD}-{short-summary}/`.
    * Initialize `plan.md` and `state.json`.
4.  **Analyze Existing Context:** Before planning, conduct a comprehensive analysis of the code and its history by reviewing all original feature artifacts:
    * **Feature Implementation Plan:** The original `features/.../plan.md`.
    * **AI Implementation Record:** The `ai-implementation/...` document.
    * **Code and Tests:** The resulting production code and its tests.
    * **Design & User Docs:** Any related `technical_design/` or `docs/`.

-----

## Phase 2: Strategic Planning

I will perform a comprehensive analysis of the `${input:source}` and project structure to create a detailed implementation plan inside the session's `plan.md`.

```markdown
# Refactoring Plan - [timestamp]

## Source Analysis
- **Target Code**: [Files/Modules to be refactored]
- **Reason for Refactoring**: [e.g., Technical debt, performance, readability]
- **Related Documentation**: [Links to ai-implementation docs, design docs, etc.]

## Current State Assessment
- **Code Complexity**: [Cyclomatic complexity, code smells, etc.]
- **Test Coverage**: [Current test coverage percentage. Identify any gaps.]
- **Dependencies**: [Internal and external dependencies of the target code.]

## Refactoring Goals
- **Primary Objective**: [e.g., "Reduce method complexity from 15 to <5"]]
- **Secondary Objectives**: [e.g., "Improve variable naming", "Extract service class"]
- **Non-Goals**: [What will not be changed, e.g., "API signature will remain the same"]

## Refactoring Tasks
A prioritized checklist of TDD cycles. Each task must be a **self-contained, actionable recipe**.

**For each task, you MUST:**
1.  **Provide Granular Steps:** Break down the task into a clear, step-by-step sequence.
2.  **Embed Specifics Directly:** If `${input:source}` provides critical details (prompts, data formats, code snippets), embed them directly within the relevant task.
3.  **Preserve References:** If `${input:source}` mentions a specific section, file path, or link, include that exact reference in the plan.
4.  **Clarify LLM Calls:** For any step involving an LLM, specify the function, expected input, and prompt.

### Example of a well-formed task:
- [ ] **Task 1.1**: HTTP endpoints duplication quick check
      - **Test:** Write a failing test for `quick_check_http_endpoints`.
      - **Implement:** Create the `quick_check_http_endpoints` function.
      - **Step 1:** Get all routes and metadata from `src.crypto_data_tools.main`.
      - **Step 2:** Format the endpoint metadata into the required JSON input as specified in the source.
      - **Step 3:** Call the LLM service using the exact prompt from the source.
      - **Step 4:** If duplicates are found, print results and exit as per the source's restrictions.
      - **Step 5:** Implement the `no-fast-check` parameter to bypass this step.

## Validation Checklist
- [ ] All existing tests are passing.
- [ ] New tests (if any) are passing.
- [ ] Test coverage has not decreased.
- [ ] Functionality is identical to the pre-refactoring state.
- [ ] Documentation is updated.
````

-----

## Phase 3: The MANDATORY Refactoring & Plan Update Cycle

You **must** follow this strict, stateful, test-driven cycle for every single task in `plan.md`. The plan is your single source of truth for your progress.

**Your step-by-step process is as follows:**

1.  **SELECT Task:** Choose the **next unchecked task** from your `plan.md`. Announce which task you are starting.
2.  **(üõ°Ô∏è VERIFY) Establish Safety Net:**
      * Run all tests relevant to the target code. **Confirm they all pass before you begin.**
      * If test coverage is insufficient, write new tests to cover existing behavior **before** refactoring. This itself may be a task in your plan.
3.  **(üîµ REFACTOR) Make Small, Atomic Change:** Apply one small, incremental refactoring step as described in the task.
4.  **(üü¢ TEST) Run Tests Immediately:** Run the test suite again.
      * **If tests pass:** Proceed to the next mandatory step.
      * **If any test fails:** You **MUST** revert the change immediately. Announce the failure and try a different, smaller approach to the same task. Do not proceed.
5.  **(‚úçÔ∏è UPDATE & COMMIT) Mark Progress in the Plan:** This step is **MANDATORY** after every successful Refactor-Test cycle that completes a task.
      * **Immediately** read the contents of `plan.md`.
      * Modify the file to mark the task you just completed as done (e.g., change `[ ]` to `[x]`).
      * Write the updated content back to `plan.md`.
      * **Present the updated checklist from the plan** to show your progress before starting the next task.
6.  **REPEAT:** Continue this **Select-Verify-Refactor-Test-Update** cycle until all tasks in `plan.md` are marked as complete.

-----

## Phase 4: Quality Assurance & Validation

This deep validation process is triggered by commands like `/refactor finish` or `/refactor verify`.

**Deep Validation Process:**

1.  Deeply analyze the original code and document its state in `refactoring/{...}/pre-refactor-analysis.md`.
2.  Verify the final code against the goals in `plan.md`.
3.  Run the complete test suite for the entire project to check for unintended side effects.
4.  Scan for TODOs, incomplete work, and potential bugs.
5.  Produce a final report comparing the pre- and post-refactoring states, including metrics like complexity and test coverage.
6.  Search for and update any relevant documentation (code comments, READMEs, etc.).
7.  Follow project conventions for documenting AI usage and implementation details.

-----

## üìù Constraints & Requirements

  * **Behavior Preservation is Mandatory:** The external behavior of the code **must not** change.
  * **Test-Driven:** **No refactoring without a passing test suite.** If tests fail, the change must be reverted.
  * **Stateful Plan Updates:** You **must** update the `plan.md` checklist *immediately* after completing each task and before starting the next. The plan must always reflect the current state of your work.
  * **High Test Coverage:** Maintain or increase existing test coverage.
  * **Session-Based Work:** All work must be done within the context of a session folder inside `refactoring/`.
  * **Global Rules:** Follow all global rules and guidelines established for the project.

-----

## ‚úÖ Success Criteria

This task is considered complete when:

  * The refactoring goals outlined in `plan.md` have been achieved.
  * All tasks in `plan.md` are checked off.
  * All unit and integration tests for the entire project are passing.
  * The refactored code is demonstrably cleaner and easier to understand.
  * The feature is functionally identical to its pre-refactoring state, with no regressions.
  * All relevant documentation has been updated.